# MapReduce Homework

Пояснения по каждой части задания

## 1. Мама, я - аналитик (обязательная часть задания, для проверки, C++ будет только в этой части)
Заготовку использовал почти как есть, понравился очень простой и прозрачный Makefile.
Для отладки использовал сохранение датасета в Excel, с вычислением среднего и дисперсии. 
В датасете были кавычки в кавычках, поэтому в хелпер для чтения CSV добавлена обработка вложенных кавычек.

## 2. Что общего между devops и бездомным? Оба хорошо разбираются в контейнерах (необязательная часть; не для проверки; для тех, кто осилит)
Репа https://github.com/tech4242/docker-hadoop-hive-parquet клонирована и запущена.
Далее, в рамках запуска с совместимыми версиями библиотеки libstdc++ выполнено создание докер-образа для сборки мапера и редьюсера.
Собранные маппер и редьюсер забрал из контейнера на локальную машину. 

## 3. Открываем мир больших данных (необязательная часть; не для проверки; для тех, кто осилит)

### HDFS
Сделано

### Hadoop Map-Reduce
На основе предоставленного скрипта для запуска hadoop map-reduce реализован скрипт run_hadoop-streaming.sh, который в свою очередь запускается из основного скрипта run_hadoop-avg-dispersion.sh
Расчет дисперсии делается также, но за основу берется датасет с добавленной первой строкой, в которой значение ранее вычисленного среднего. 


